[37m[36mINFO[0m[0m::02/20 20:13:07 | Run Argv:
> C:/Users/simba/Desktop/fewshot-font-generation-main/train_MX.py cfgs/MX/train.yaml cfgs/data/train/custom.yaml
[37m[36mINFO[0m[0m::02/20 20:13:07 | Args:
config_paths  = ['cfgs/MX/train.yaml', 'cfgs/data/train/custom.yaml']
nodes         = 1
gpus_per_node = 1
nr            = 0
port          = 13481
verbose       = True
world_size    = 1
[37m[36mINFO[0m[0m::02/20 20:13:07 | Configs:
seed: 2
model: mx
decomposition: data/chn/decomposition.json
primals: data/chn/primals.json
max_iter: 800000
g_lr: 0.0002
d_lr: 0.001
ac_lr: 0.0002
adam_betas: 
  - 0.0
  - 0.9
trainer: 
  resume: None
  force_resume: False
  work_dir: result\mx
  pixel_loss_type: l1
  pixel_w: 0.1
  gan_w: 1.0
  fm_layers: all
  fm_w: 1.0
  ac_w: 1.0
  ac_gen_w: 1.0
  ac_cross_w: 0.0
  indp_exp_w: 1.0
  indp_fact_w: 1.0
  save: all-last
  print_freq: 1000
  val_freq: 10000
  save_freq: 50000
  tb_freq: 100
gen: 
  n_experts: 6
  n_emb: 2
dset: 
  loader: 
    batch_size: 8
    num_workers: 16
  train: 
    n_in_s: 3
    n_in_c: 3
    data_dir: data_example/chn/ttf
    chars: data/chn/train_chars.json
    extension: ttf
  val: 
    unseen_chars: 
      data_dir: data_example/chn/ttf
      extension: ttf
      n_gen: 20
      n_font: 5
      chars: data/chn/val_unseen_chars.json
      source_path: data/chn/source.ttf
      source_ext: ttf
    seen_chars: 
      data_dir: data_example/chn/ttf
      extension: ttf
      n_gen: 20
      n_font: 5
      chars: data/chn/val_seen_chars.json
      source_path: data/chn/source.ttf
      source_ext: ttf
use_ddp: False
[37m[36mINFO[0m[0m::02/20 20:13:13 | [0] Get dataset ...
[37m[36mINFO[0m[0m::02/20 20:13:13 | [0] Build model ...
[37m[36mINFO[0m[0m::02/20 20:13:18 | Start training ...
[37m[36mINFO[0m[0m::02/20 20:25:02 | Run Argv:
> C:/Users/simba/Desktop/fewshot-font-generation-main/train_MX.py cfgs/MX/train.yaml cfgs/data/train/custom.yaml
[37m[36mINFO[0m[0m::02/20 20:25:02 | Args:
config_paths  = ['cfgs/MX/train.yaml', 'cfgs/data/train/custom.yaml']
nodes         = 1
gpus_per_node = 1
nr            = 0
port          = 13481
verbose       = True
world_size    = 1
[37m[36mINFO[0m[0m::02/20 20:25:02 | Configs:
seed: 2
model: mx
decomposition: data/chn/decomposition.json
primals: data/chn/primals.json
max_iter: 800000
g_lr: 0.0002
d_lr: 0.001
ac_lr: 0.0002
adam_betas: 
  - 0.0
  - 0.9
trainer: 
  resume: None
  force_resume: False
  work_dir: result\mx
  pixel_loss_type: l1
  pixel_w: 0.1
  gan_w: 1.0
  fm_layers: all
  fm_w: 1.0
  ac_w: 1.0
  ac_gen_w: 1.0
  ac_cross_w: 0.0
  indp_exp_w: 1.0
  indp_fact_w: 1.0
  save: all-last
  print_freq: 1000
  val_freq: 10000
  save_freq: 50000
  tb_freq: 100
gen: 
  n_experts: 6
  n_emb: 2
dset: 
  loader: 
    batch_size: 8
    num_workers: 16
  train: 
    n_in_s: 3
    n_in_c: 3
    data_dir: data_example/chn/ttf
    chars: data/chn/train_chars.json
    extension: ttf
  val: 
    unseen_chars: 
      data_dir: data_example/chn/ttf
      extension: ttf
      n_gen: 20
      n_font: 5
      chars: data/chn/val_unseen_chars.json
      source_path: data/chn/source.ttf
      source_ext: ttf
    seen_chars: 
      data_dir: data_example/chn/ttf
      extension: ttf
      n_gen: 20
      n_font: 5
      chars: data/chn/val_seen_chars.json
      source_path: data/chn/source.ttf
      source_ext: ttf
use_ddp: False
[37m[36mINFO[0m[0m::02/20 20:25:04 | [0] Get dataset ...
[37m[36mINFO[0m[0m::02/20 20:25:04 | [0] Build model ...
[37m[36mINFO[0m[0m::02/20 20:25:06 | Start training ...
[37m[36mINFO[0m[0m::02/21 10:44:29 | Run Argv:
> C:/Users/simba/Desktop/fewshot-font-generation-main/train_MX.py cfgs/MX/train.yaml cfgs/data/train/custom.yaml
[37m[36mINFO[0m[0m::02/21 10:44:29 | Args:
config_paths  = ['cfgs/MX/train.yaml', 'cfgs/data/train/custom.yaml']
nodes         = 1
gpus_per_node = 1
nr            = 0
port          = 13481
verbose       = True
world_size    = 1
[37m[36mINFO[0m[0m::02/21 10:44:29 | Configs:
seed: 2
model: mx
decomposition: data/chn/decomposition.json
primals: data/chn/primals.json
max_iter: 800000
g_lr: 0.0002
d_lr: 0.001
ac_lr: 0.0002
adam_betas: 
  - 0.0
  - 0.9
trainer: 
  resume: None
  force_resume: False
  work_dir: result\mx
  pixel_loss_type: l1
  pixel_w: 0.1
  gan_w: 1.0
  fm_layers: all
  fm_w: 1.0
  ac_w: 1.0
  ac_gen_w: 1.0
  ac_cross_w: 0.0
  indp_exp_w: 1.0
  indp_fact_w: 1.0
  save: all-last
  print_freq: 1000
  val_freq: 10000
  save_freq: 50000
  tb_freq: 100
gen: 
  n_experts: 6
  n_emb: 2
dset: 
  loader: 
    batch_size: 8
    num_workers: 16
  train: 
    n_in_s: 3
    n_in_c: 3
    data_dir: data_example/chn/ttf
    chars: data/chn/train_chars.json
    extension: ttf
  val: 
    unseen_chars: 
      data_dir: data_example/chn/ttf
      extension: ttf
      n_gen: 20
      n_font: 5
      chars: data/chn/val_unseen_chars.json
      source_path: data/chn/source.ttf
      source_ext: ttf
    seen_chars: 
      data_dir: data_example/chn/ttf
      extension: ttf
      n_gen: 20
      n_font: 5
      chars: data/chn/val_seen_chars.json
      source_path: data/chn/source.ttf
      source_ext: ttf
use_ddp: False
[37m[36mINFO[0m[0m::02/21 10:44:36 | [0] Get dataset ...
[37m[36mINFO[0m[0m::02/21 10:44:36 | [0] Build model ...
[37m[36mINFO[0m[0m::02/21 10:44:40 | Start training ...
